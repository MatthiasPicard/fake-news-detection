{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tldextract\n",
    "import numpy as np\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.datasets import MovieLens\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_mentions = [\"GlobalEventID\",\"EventTimeDate\",\"MentionTimeDate\",\"MentionType\",\n",
    "        \"MentionSourceName\",\"MentionIdentifier\",\"SentenceID\",\"Actor1CharOffset\",\"Actor2CharOffset\",\n",
    "        \"ActionCharOffset\",\"InRawText\",\"Confidence\",\"MentionDocLen\",\"MentionDocTone\",\n",
    "        \"SRCLC\", \"ENG\"] # mention columns\n",
    "\n",
    "col_names_events = [\"GlobalEventID\",\"Day\",\"MonthYear\",\"Year\",\"FractionDate\",\n",
    "                            \"Actor1Code\",\"Actor1Name\",\"Actor1CountryCode\",\"Actor1KnownGroupCode\",\"Actor1EthnicCode\",\n",
    "                            \"Actor1Religion1Code\",\"Actor1Religion2Code\",\"Actor1Type1Code\",\"Actor1Type2Code\",\"Actor1Type3Code\",\n",
    "                            \"Actor2Code\",\"Actor2Name\",\"Actor2CountryCode\",\"Actor2KnownGroupCode\",\"Actor2EthnicCode\",\n",
    "                            \"Actor2Religion1Code\",\"Actor2Religion2Code\",\"Actor2Type1Code\",\"Actor2Type2Code\",\"Actor2Type3Code\",\n",
    "                            \"IsRootEvent\",\"EventCode\",\"EventBaseCode\",\"EventRootCode\",\"QuadClass\",\n",
    "                            \"GoldsteinScale\",\"NumMentions\",\"NumSources\",\"NumArticles\",\"AvgTone\",\n",
    "                            \"Actor1Geo_Type\",\"Actor1Geo_Fullname\",\"Actor1Geo_CountryCode\",\"Actor1Geo_ADM1Code\",\"Actor1Geo_ADM2Code\",\n",
    "                            \"Actor1Geo_Lat\",\"Actor1Geo_Long\",\"Actor1Geo_FeatureID\",\"Actor2Geo_Type\",\"Actor2Geo_Fullname\",\n",
    "                            \"Actor2Geo_CountryCode\",\"Actor2Geo_ADM1Code\",\"Actor2Geo_ADM2Code\",\"Actor2Geo_Lat\",\"Actor2Geo_Long\",\n",
    "                            \"Actor2Geo_FeatureID\",\"ActionGeo_Type\",\"ActionGeo_Fullname\",\"ActionGeo_CountryCode\",\"ActionGeo_ADM1Code\",\n",
    "                            \"ActionGeo_ADM2Code\",\"ActionGeo_Lat\",\"ActionGeo_Long\",\"ActionGeo_FeatureID\",\"DATEADDED\",\n",
    "                            \"SOURCEURL\"] # event columns\n",
    "\n",
    "with open(\"urls_to_download_fr.pkl\", 'rb') as file: # label of articles (0 if fake or not present in MBFS)\n",
    "    df_mentions = pickle.load(file)\n",
    "    \n",
    "with open(\"labeled sources.pkl\", 'rb') as file: # label of sources (0 if fake or not present in MBFS)\n",
    "    df_sources = pickle.load(file)\n",
    "    \n",
    "with open(\"mixt_labeled_sources.pkl\", 'rb') as file: # label of sources (nan if not present in MBFS)\n",
    "    df_sources_mixte = pickle.load(file)\n",
    "    \n",
    "with open(\"mixt_labeled_articles.pkl\", 'rb') as file: # label of articles (nan if not present in MBFS)\n",
    "    df_articles_mixte = pickle.load(file)\n",
    "\n",
    "MBFS = pd.read_csv(\"../mediabiasfactcheck/mediabiasfactcheck.csv\")\n",
    "\n",
    "df_test = pd.read_csv(\"gdelt_data/20231001000000.mentions.CSV\", delimiter='\\t', names=col_names_mentions)\n",
    "\n",
    "df_test_event = pd.read_csv(\"gdelt_data_event/20231001000000.export.CSV\", delimiter='\\t', names=col_names_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "# Data Analysis\n",
    "    # number of articles by source and compare this stat with the fact that they could be fake\n",
    "    # count the number of labelized elements in each relevant label dataset\n",
    "    # number of csv mentions/events in october 2023\n",
    "    # number of csv events in october 2023\n",
    "    # number of articles/sources in total\n",
    "    # number of nans in each columns\n",
    "    # look at sources type in mention and evaluate impact\n",
    "    \n",
    "    \n",
    "# Data Processing\n",
    "    # remove irrelevant columns/nans?\n",
    "    # put them in the correct format for graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fake\n",
       "NaN    0.920925\n",
       "0.0    0.076651\n",
       "1.0    0.002423\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sources_mixte[\"is_fake\"].value_counts(dropna = False) /len(df_sources_mixte[\"is_fake\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fake\n",
       "NaN    0.744008\n",
       "0.0    0.248798\n",
       "1.0    0.007194\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles_mixte[\"is_fake\"].value_counts(dropna = False)/len(df_articles_mixte[\"is_fake\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                    0.043817\n",
       "name                   0.000269\n",
       "image_pseudoscience    0.900000\n",
       "image_factual          0.081720\n",
       "image_conspiracy       0.908333\n",
       "image_bias             0.149462\n",
       "freedom_rank           0.593817\n",
       "country                0.546237\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MBFS.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>infiniteunknown.net</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sott.net</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>dailymail.co.uk</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>wordpress.com</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>oann.com</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   links  is_fake\n",
       "15   infiniteunknown.net      1.0\n",
       "54              sott.net      1.0\n",
       "102      dailymail.co.uk      1.0\n",
       "131        wordpress.com      1.0\n",
       "163             oann.com      1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sources_mixte[df_sources_mixte[\"is_fake\"] == 1.0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>https://www.oann.com/newsroom/death-toll-rises...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>https://www.oann.com/newsroom/man-accused-of-k...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29234</th>\n",
       "      <td>https://www.oann.com/newsroom/dem-rep-jamaal-b...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29364</th>\n",
       "      <td>https://www.oann.com/newsroom/girl-9-disappear...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36554</th>\n",
       "      <td>https://www.oann.com/newsroom/breonna-taylors-...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908385</th>\n",
       "      <td>https://www.oann.com/newsroom/israeli-military...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908605</th>\n",
       "      <td>https://www.oann.com/business/us-seeks-to-bloc...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925791</th>\n",
       "      <td>https://www.oann.com/newsroom/person-of-intere...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926135</th>\n",
       "      <td>https://www.oann.com/newsroom/fbi-chief-christ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926139</th>\n",
       "      <td>https://www.oann.com/newsroom/u-s-unveils-nucl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     links  is_fake\n",
       "341      https://www.oann.com/newsroom/death-toll-rises...      1.0\n",
       "688      https://www.oann.com/newsroom/man-accused-of-k...      1.0\n",
       "29234    https://www.oann.com/newsroom/dem-rep-jamaal-b...      1.0\n",
       "29364    https://www.oann.com/newsroom/girl-9-disappear...      1.0\n",
       "36554    https://www.oann.com/newsroom/breonna-taylors-...      1.0\n",
       "...                                                    ...      ...\n",
       "1908385  https://www.oann.com/newsroom/israeli-military...      1.0\n",
       "1908605  https://www.oann.com/business/us-seeks-to-bloc...      1.0\n",
       "1925791  https://www.oann.com/newsroom/person-of-intere...      1.0\n",
       "1926135  https://www.oann.com/newsroom/fbi-chief-christ...      1.0\n",
       "1926139  https://www.oann.com/newsroom/u-s-unveils-nucl...      1.0\n",
       "\n",
       "[275 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles_mixte[df_articles_mixte[\"links\"].str.contains(\"oann.com\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>image_pseudoscience</th>\n",
       "      <th>image_factual</th>\n",
       "      <th>image_conspiracy</th>\n",
       "      <th>image_bias</th>\n",
       "      <th>freedom_rank</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>https://www.oann.com</td>\n",
       "      <td>One America News Network (OAN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MBFCLow.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right.?.?.?.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url                            name image_pseudoscience  \\\n",
       "468  https://www.oann.com  One America News Network (OAN)                 NaN   \n",
       "\n",
       "    image_factual image_conspiracy       image_bias freedom_rank country  \n",
       "468   MBFCLow.png              NaN  right.?.?.?.png          NaN     NaN  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MBFS = MBFS.dropna(subset=['url'])\n",
    "MBFS[MBFS[\"url\"].str.contains(\"oann.com\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_count for mentions: 2974\n",
      "total number of lines for mentions: 14485980\n",
      "percentage of nan for each column: GlobalEventID        0.000000e+00\n",
      "EventTimeDate        0.000000e+00\n",
      "MentionTimeDate      0.000000e+00\n",
      "MentionType          0.000000e+00\n",
      "MentionSourceName    8.460116e-07\n",
      "MentionIdentifier    0.000000e+00\n",
      "SentenceID           0.000000e+00\n",
      "Actor1CharOffset     0.000000e+00\n",
      "Actor2CharOffset     0.000000e+00\n",
      "ActionCharOffset     0.000000e+00\n",
      "InRawText            0.000000e+00\n",
      "Confidence           0.000000e+00\n",
      "MentionDocLen        0.000000e+00\n",
      "MentionDocTone       0.000000e+00\n",
      "SRCLC                1.000000e+00\n",
      "ENG                  1.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "csv_count = 0\n",
    "total = 0\n",
    "nan = 0\n",
    "\n",
    "for root, _, filenames in os.walk(\"gdelt_data\"):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".CSV\"):\n",
    "            csv_count += 1\n",
    "            temp = pd.read_csv(os.path.join(root, filename), delimiter='\\t', names=col_names_mentions)\n",
    "            nan += temp.isna().mean()\n",
    "            total+=len(temp)\n",
    "\n",
    "print(\"csv_count for mentions: \"+str(csv_count))\n",
    "print(\"total number of lines for mentions: \"+str(total))\n",
    "print(\"percentage of nan for each column: \"+str(nan/csv_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_count for events: 2974\n",
      "total number of lines for events: 4606957\n",
      "percentage of nan for each column: GlobalEventID          0.000000\n",
      "Day                    0.000000\n",
      "MonthYear              0.000000\n",
      "Year                   0.000000\n",
      "FractionDate           0.000000\n",
      "                         ...   \n",
      "ActionGeo_Lat          0.024224\n",
      "ActionGeo_Long         0.024117\n",
      "ActionGeo_FeatureID    0.023964\n",
      "DATEADDED              0.000000\n",
      "SOURCEURL              0.000000\n",
      "Length: 61, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "csv_count = 0\n",
    "total = 0\n",
    "nan = 0\n",
    "\n",
    "for root, _, filenames in os.walk(\"gdelt_data_event\"):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".CSV\"):\n",
    "            csv_count += 1\n",
    "            temp = pd.read_csv(os.path.join(root, filename), delimiter='\\t', names=col_names_events) \n",
    "            total+=len(temp)\n",
    "            nan += temp.isna().mean()\n",
    "\n",
    "\n",
    "print(\"csv_count for events: \"+str(csv_count))\n",
    "print(\"total number of lines for events: \"+str(total))\n",
    "print(\"percentage of nan for each column: \"+str(nan/csv_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MentionType\n",
      "1    14485980\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_count = 0\n",
    "csv_count = 0\n",
    "\n",
    "for root, _, filenames in os.walk(\"gdelt_data\"):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".CSV\"):\n",
    "            csv_count += 1\n",
    "            temp = pd.read_csv(os.path.join(root, filename), delimiter='\\t', names=col_names_mentions)\n",
    "            value_count += temp[\"MentionType\"].value_counts()\n",
    "            if len(temp[\"MentionType\"].value_counts())>1:\n",
    "                print(\"omg\")\n",
    "\n",
    "            \n",
    "print(value_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcessing -> put in graph format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "dataset = MovieLens(root='data/MovieLens', transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MovieLens():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: {'movie': 404, 'user': 0}\n",
      "\n",
      "HeteroData(\n",
      "  movie={ x=[9742, 404] },\n",
      "  user={ num_nodes=610 },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 100836],\n",
      "    edge_label=[100836],\n",
      "  }\n",
      ")\n",
      "===========================================================================================================\n",
      "Number of nodes: 10352\n",
      "Number of edges: 100836\n",
      "Average node degree: 9.74\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "# print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========================================================================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "# print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "# print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0.0016, 0.0028, 0.0028,  ..., 0.0024, 0.0024, 0.0024],\n",
       "        [0.0014, 0.0038, 0.0022,  ..., 0.0024, 0.0024, 0.0024],\n",
       "        [0.0015, 0.0026, 0.0019,  ..., 0.0024, 0.0024, 0.0024],\n",
       "        ...,\n",
       "        [0.0014, 0.0027, 0.0023,  ..., 0.0024, 0.0024, 0.0024],\n",
       "        [0.0028, 0.0026, 0.0027,  ..., 0.0024, 0.0024, 0.0024],\n",
       "        [0.0020, 0.0023, 0.0024,  ..., 0.0024, 0.0024, 0.0024]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data[\"user\", \"rates\", \"movie\"].edge_index\n",
    "# data[\"movie\"]\n",
    "data[\"movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_nx = to_networkx(data)\n",
    "\n",
    "# # Visualize the graph using NetworkX\n",
    "# pos = nx.spring_layout(g_nx)\n",
    "# nx.draw(g_nx, pos, with_labels=True, node_color='skyblue', font_weight='bold', font_color='black', node_size=800, edge_color='gray')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# df_test['MentionSourceName'] = label_encoder.fit_transform(df_test['MentionSourceName'])\n",
    "# label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "# label_encoder_article = LabelEncoder()\n",
    "# df_test['MentionIdentifier'] = label_encoder_article.fit_transform(df_test['MentionIdentifier'])\n",
    "# label_mapping_article = dict(zip(label_encoder_article.classes_, label_encoder_article.transform(label_encoder_article.classes_)))\n",
    "\n",
    "# label_encoder_event = LabelEncoder()\n",
    "# df_test['GlobalEventID'] = label_encoder_event.fit_transform(df_test['GlobalEventID'])\n",
    "# label_mapping_event = dict(zip(label_encoder_event.classes_, label_encoder_event.transform(label_encoder_event.classes_)))\n",
    "# df_test_event['GlobalEventID'] = df_test_event['GlobalEventID'].map(label_mapping_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and creating the map for df_sources\n",
    "\n",
    "label_encoder_source = LabelEncoder()\n",
    "df_sources_mixte['links'] = label_encoder_source.fit_transform(df_sources_mixte['links'])\n",
    "label_mapping_source = dict(zip(label_encoder_source.classes_, label_encoder_source.transform(label_encoder_source.classes_)))\n",
    "# df_sources_mixte['links'] = df_sources_mixte['links'].map(label_mapping_source)\n",
    "\n",
    "df_sources_mixte_sorted = df_sources_mixte.sort_values(by=\"links\").set_index(\"links\")\n",
    "df_sources_mixte_sorted = df_sources_mixte_sorted.reset_index(drop=False)\n",
    "mapping_source = df_sources_mixte_sorted[\"links\"]\n",
    "df_sources_mixte_sorted[\"random\"] = np.random.rand(14442)\n",
    "y = df_sources_mixte_sorted[\"is_fake\"]\n",
    "df_sources_mixte_sorted = df_sources_mixte_sorted[[\"random\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and creating the map for df_article\n",
    "\n",
    "df_article = pd.DataFrame(df_test[\"MentionIdentifier\"])\n",
    "\n",
    "label_encoder_article = LabelEncoder()\n",
    "df_article['MentionIdentifier'] = label_encoder_article.fit_transform(df_article['MentionIdentifier'])\n",
    "label_mapping_article = dict(zip(label_encoder_article.classes_, label_encoder_article.transform(label_encoder_article.classes_)))\n",
    "\n",
    "df_article_sorted = df_article.sort_values(by=\"MentionIdentifier\").set_index(\"MentionIdentifier\")\n",
    "df_article_sorted = df_article_sorted.reset_index(drop=False)\n",
    "mapping_article = df_article_sorted[\"MentionIdentifier\"]\n",
    "df_article_sorted[\"random\"] = np.random.rand(1855)\n",
    "df_article_sorted = df_article_sorted[[\"random\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and creating the map for df_event\n",
    "\n",
    "label_encoder_event = LabelEncoder()\n",
    "df_test_event['GlobalEventID'] = label_encoder_event.fit_transform(df_test_event['GlobalEventID'])\n",
    "label_mapping_event = dict(zip(label_encoder_event.classes_, label_encoder_event.transform(label_encoder_event.classes_)))\n",
    "# df_test_event['GlobalEventID'] = df_test_event['GlobalEventID'].map(label_mapping_event)\n",
    "df_test_event_sorted = df_test_event.sort_values(by=\"GlobalEventID\").set_index(\"GlobalEventID\")\n",
    "df_test_event_sorted = df_test_event_sorted.reset_index(drop=False)\n",
    "mapping_event = df_test_event_sorted[\"GlobalEventID\"]\n",
    "df_test_event_sorted = df_test_event_sorted.drop(\"GlobalEventID\",axis = 1)\n",
    "df_test_event_sorted = df_test_event_sorted.drop(\"GlobalEventID\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding all the keys in the mention dataset\n",
    "\n",
    "df_test['MentionIdentifier'] = df_test['MentionIdentifier'].map(label_mapping_article)\n",
    "df_test['MentionSourceName'] = df_test['MentionSourceName'].map(label_mapping_source)\n",
    "df_test['GlobalEventID'] = df_test['GlobalEventID'].map(label_mapping_event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_source_de = df_test[[\"MentionSourceName\",\"MentionIdentifier\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0\n",
       "1            1\n",
       "2            2\n",
       "3            3\n",
       "4            4\n",
       "         ...  \n",
       "14437    14437\n",
       "14438    14438\n",
       "14439    14439\n",
       "14440    14440\n",
       "14441    14441\n",
       "Name: links, Length: 14442, dtype: int32"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_46416\\505668169.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  est_source_de[\"MentionSourceName\"] = est_source_de[\"MentionSourceName\"].map(source_map[\"index\"]).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Mapping articles and sources to create edges of type \"df_test_event_sorted\"\n",
    "\n",
    "article_map = mapping_article.reset_index().set_index(\"MentionIdentifier\").to_dict()\n",
    "est_source_de[\"MentionIdentifier\"] = est_source_de[\"MentionIdentifier\"].map(article_map[\"index\"]).astype(int)\n",
    "\n",
    "source_map = mapping_source.reset_index().set_index(\"links\").to_dict()\n",
    "est_source_de[\"MentionSourceName\"] = est_source_de[\"MentionSourceName\"].map(source_map[\"index\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  461,  5199,  7027, ..., 10925, 10925, 10925],\n",
       "       [  464,   879,   337, ...,  1395,  1395,  1395]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_est_source_de = est_source_de[[\"MentionSourceName\", \"MentionIdentifier\"]].values.transpose()\n",
    "edge_est_source_de # [2 x num_edges] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the first csv of events mentions and sources to start\n",
    "\n",
    "\n",
    "data = HeteroData()\n",
    "data['articles'] = df_article_sorted.to_numpy()\n",
    "data['sources'] = df_sources_mixte_sorted.to_numpy()\n",
    "data['events'].x = df_test_event_sorted.to_numpy()\n",
    "\n",
    "data['event', 'mentionné', 'article'].edge_attr\n",
    "\n",
    "data['event', 'mentionné', 'article'].edge_index\n",
    "data['source', 'est_source_de', 'article'].edge_index = edge_est_source_de"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
