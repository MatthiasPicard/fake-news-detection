{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af661ce0-6cd1-4cdc-9037-e08b1bb3d7a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilel\\PycharmProjects\\FakeNews\\fake-news-detection\\preprocessing.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  est_source_de[self.non_label_column] = est_source_de[self.non_label_column].map(article_map[\"index\"]).astype(int)\n",
      "C:\\Users\\bilel\\PycharmProjects\\FakeNews\\fake-news-detection\\preprocessing.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  est_source_de[self.label_column] = est_source_de[self.label_column].map(source_map[\"index\"]) # Bugfix attempt, may be suboptimal\n",
      "C:\\Users\\bilel\\PycharmProjects\\FakeNews\\fake-news-detection\\preprocessing.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mentionné[\"MentionIdentifier\"] = mentionné[\"MentionIdentifier\"].map(article_map[\"index\"]).astype(int)\n",
      "C:\\Users\\bilel\\PycharmProjects\\FakeNews\\fake-news-detection\\preprocessing.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mentionné[\"GlobalEventID\"] = mentionné[\"GlobalEventID\"].map(event_map[\"index\"])\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m fake_news_detector \u001b[38;5;241m=\u001b[39m SimpleConnexionsHAN(label,device) \n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# fake_news_detector = CloseEventsConnexionsHAN(label,device) \u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[43mfake_news_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_graph_and_train_on_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_simple_connexions_HAN_1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\FakeNews\\fake-news-detection\\TrainingService.py:36\u001b[0m, in \u001b[0;36mSimpleConnexionsHAN.create_graph_and_train_on_model\u001b[1;34m(self, list_event, list_mention, hidden_channels, out_channels, n_heads, nb_epoch, lr, weight_decay, dropout)\u001b[0m\n\u001b[0;32m     31\u001b[0m labels,df_events,df_mentions \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mdata_load(list_event,list_mention)\n\u001b[0;32m     32\u001b[0m data \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mcreate_graph(labels,df_events,df_mentions)\n\u001b[1;32m---> 36\u001b[0m sampler \u001b[38;5;241m=\u001b[39m \u001b[43mImbalancedSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m loader \u001b[38;5;241m=\u001b[39m NeighborLoader(data, input_nodes\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtrain_mask,\n\u001b[0;32m     38\u001b[0m                         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, num_neighbors\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     39\u001b[0m                         sampler\u001b[38;5;241m=\u001b[39msampler)\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m HAN(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel,metadata \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mmetadata(),\n\u001b[0;32m     42\u001b[0m             hidden_channels\u001b[38;5;241m=\u001b[39mhidden_channels,\n\u001b[0;32m     43\u001b[0m             out_channels\u001b[38;5;241m=\u001b[39mout_channels,\n\u001b[0;32m     44\u001b[0m             n_heads\u001b[38;5;241m=\u001b[39mn_heads,\n\u001b[0;32m     45\u001b[0m             dropout \u001b[38;5;241m=\u001b[39m dropout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DeepL\\lib\\site-packages\\torch_geometric\\loader\\imbalanced_sampler.py:85\u001b[0m, in \u001b[0;36mImbalancedSampler.__init__\u001b[1;34m(self, dataset, input_nodes, num_samples)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     ys \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39my \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ys[\u001b[38;5;241m0\u001b[39m], Tensor):\n\u001b[0;32m     87\u001b[0m         y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(ys, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DeepL\\lib\\site-packages\\torch_geometric\\data\\feature_store.py:515\u001b[0m, in \u001b[0;36mFeatureStore.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from SimplePreprocessing import SimplePreprocessing\n",
    "from heterogemodel import HAN\n",
    "from Training import SimpleTraining\n",
    "from TrainingService import SimpleConnexionsHAN,CloseEventsConnexionsHAN\n",
    "\n",
    "\n",
    "from GraphViz import GraphViz\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "def get_csv_files(directory, n):\n",
    "    csv_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".CSV\"):\n",
    "            # print(os.path.join(directory, filename))\n",
    "            csv_files.append(os.path.join(directory, filename))\n",
    "            if len(csv_files) == n:\n",
    "                break\n",
    "    return csv_files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    nb_event_csv = 16 # TODO: fail at 17 if label = source ( bug fixé mais un peu à la zob)\n",
    "    nb_mentions_csv = 1\n",
    "    list_mention = get_csv_files(\"gdelt_data\", nb_mentions_csv)\n",
    "    list_event = get_csv_files(\"gdelt_data_event\",nb_event_csv)\n",
    "\n",
    "    label = \"source\"\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device ('cpu')\n",
    "    args_simple_connexions_HAN_1 = {\n",
    "    \"list_mention\": list_mention,\n",
    "    \"list_event\":list_event,\n",
    "    \n",
    "    \"hidden_channels\": 64,\n",
    "    \"out_channels\": 2,\n",
    "    \"n_heads\": 4,\n",
    "    \"dropout\": 0.5,\n",
    "    \"nb_epoch\": 10,\n",
    "    \"lr\": 0.005,\n",
    "    \"weight_decay\":0.001\n",
    "    \n",
    "    }\n",
    "       \n",
    "    fake_news_detector = SimpleConnexionsHAN(label,device) \n",
    "    # fake_news_detector = CloseEventsConnexionsHAN(label,device) \n",
    "    fake_news_detector.create_graph_and_train_on_model(**args_simple_connexions_HAN_1)\n",
    "    \n",
    "    # TODO: create a function to save model\n",
    "    # TODO faire en sorte que les resultats soient reproductibles\n",
    "    \n",
    "    # analyse = GraphViz(label,list_event,list_mention)\n",
    "    # analyse.get_recap()\n",
    "    # analyse.display_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801bb5a5-de35-4c59-a7ab-e831aa9bfec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
